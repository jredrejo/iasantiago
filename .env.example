TZ=Europe/Madrid

# ========= VLLM =========
VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct
VLLM_GPU_MEMORY_UTILIZATION=0.90
VLLM_MAX_MODEL_LEN=8192
VLLM_TENSOR_PARALLEL_SIZE=1

# Optimizaciones para latencia
VLLM_MAX_NUM_SEQS=256            # Mantén esto alto para throughput
VLLM_MAX_NUM_BATCHED_TOKENS=8192 # Match con max_model_len
VLLM_BLOCK_SIZE=16               # Eficiencia de memory

# ========= EMBEDDINGS & RERANKER =========
# Dense embedder por defecto (multilingüe, bueno para ES+PDF)
EMBED_MODEL_DEFAULT=intfloat/multilingual-e5-large-instruct
# Embedders por tema (opcional; vacío => usa default)
EMBED_MODEL_PROGRAMMING=thenlper/gte-large
EMBED_MODEL_ELECTRONICS=intfloat/multilingual-e5-large-instruct
EMBED_MODEL_CHEMISTRY=hkunlp/instructor-large
# Reranker (cross-encoder)
RERANK_MODEL=jinaai/jina-reranker-v2-base-multilingual
# Alternativa: BAAI/bge-reranker-large
# RERANK_MODEL=BAAI/bge-reranker-v2-m3

# === Límites ===
CTX_TOKENS_SOFT_LIMIT=4000
CTX_TOKENS_GENERATIVE=10000


MAX_CHUNKS_PER_FILE=4
HYBRID_DENSE_K=50
HYBRID_BM25_K=50
FINAL_TOPK=8

# fallback a BM25 si consulta < 4 tokens
BM25_FALLBACK_TOKEN_THRESHOLD=4


# === Qdrant ===
QDRANT_URL=http://qdrant:6333
QDRANT_STORAGE=/opt/iasantiago-rag/data/storage

# === BM25 (Whoosh) ===
BM25_BASE_DIR=/opt/iasantiago-rag/data/whoosh

# === Telemetría ===
TELEMETRY_PATH=/opt/iasantiago-rag/rag-api/retrieval.jsonl

# ========= OPENAI-COMPAT / TOPIC SELECTOR =========
TOPIC_BASE_DIR=/opt/iasantiago-rag/topics
# Etiquetas que verá Open WebUI en el desplegable de modelos
TOPIC_LABELS="Chemistry,Electronics,Programming,Sostenibilidad"
# Nombre base visto por Open WebUI
OPENAI_BASE_NAME="topic"

# Cuando OWUI llama /v1/models, exponemos:
#   topic:Chemistry / topic:Electronics / topic:Programming

# ========= SECURITY / AUTH =========
# OAuth2-Proxy
OAUTH2_CLIENT_ID=CHANGEME_GOOGLE_CLIENT_ID
OAUTH2_CLIENT_SECRET=CHANGEME_GOOGLE_CLIENT_SECRET
OAUTH2_REDIRECT_URL=https://ia.santiagoapostol.net/oauth2/callback
OAUTH2_EMAIL_DOMAINS=santiagoapostol.net


OAUTH2_PROXY_REDIRECT_URL=https://ia.santiagoapostol.net/oauth2/callback
OAUTH2_PROXY_WHITELIST_DOMAIN=.santiagoapostol.net
OAUTH2_PROXY_COOKIE_DOMAIN=.santiagoapostol.net
OAUTH2_PROXY_COOKIE_SECURE=true
OAUTH2_PROXY_COOKIE_SAMESITE=None
# Genera 32 bytes aleatorios en hex para OAUTH2_COOKIE_SECRET
# python -c "import secrets; print(secrets.token_hex(16))"
OAUTH2_COOKIE_SECRET=CALCULA_USANDO_EL_COMANDO_ANTERIOR

# ========= NGINX SSL (self-signed o reales si tenéis CA interna)
SSL_CERT_PATH=/etc/nginx/ssl/iasantiago.crt
SSL_KEY_PATH=/etc/nginx/ssl/iasantiago.key

# === Open WebUI ===
OPENWEBUI_PORT=8080

# ========= BACKUP =========
BACKUP_DIR=/opt/backups/rag-system


# === OpenAI compat ===
UPSTREAM_OPENAI_URL=http://vllm:8000/v1
OPENAI_API_KEY=dummy-key   # OpenWebUI requiere algo


# CUDA Configuration
# Para RTX 5090 (Blackwell): 10.0
# Para RTX 4090/4080/4070: 8.9
# Para RTX 3090/3080/3070: 8.6
# Para RTX 2080/2070: 7.5
# Para GTX 1080/1070: 6.1
# Si no estás seguro, deja en blanco o usa "native"
TORCH_CUDA_ARCH_LIST=native

# Embedding Configuration
# Opciones: "cuda" o "cpu"
# Si tienes problemas con GPU, usa "cpu"
EMBEDDING_DEVICE=cuda

# Dtype para embeddings
# Opciones: "float16" (ahorra memoria) o "float32" (más estable)
EMBEDDING_DTYPE=float32

# Debug CUDA (descomenta para debugging)
# CUDA_LAUNCH_BLOCKING=1
# TORCH_USE_CUDA_DSA=1
