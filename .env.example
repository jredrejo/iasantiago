# ========= NETWORK / BINDINGS =========
HOST_IP=172.23.120.11
RAG_API_PORT=8001
VLLM_PORT=8000
OAUTH2_PROXY_PORT=4180
NGINX_SSL_PORT=443
COMPOSE_PROJECT_NAME=iasantiago
TZ=Europe/Madrid

# ========= VLLM =========
VLLM_MODEL=Qwen/Qwen2.5-7B-Instruct
VLLM_TRUST_REMOTE_CODE=false
VLLM_GPU_MEMORY_UTILIZATION=0.90
VLLM_MAX_MODEL_LEN=8192
VLLM_TP_SIZE=1
VLLM_TENSOR_PARALLEL_SIZE=1

# Optimizaciones para latencia
VLLM_MAX_NUM_SEQS=256            # Mantén esto alto para throughput
VLLM_MAX_NUM_BATCHED_TOKENS=8192 # Match con max_model_len
VLLM_BLOCK_SIZE=16               # Eficiencia de memory
TORCH_CUDA_ARCH_LIST=10.0 # RTX 5090 (Blackwell), 8.6 para RTX 4000 SFF (Ampere)

# ========= EMBEDDINGS & RERANKER =========
# Dense embedder por defecto (multilingüe, bueno para ES+PDF)
EMBED_MODEL_DEFAULT=intfloat/multilingual-e5-large-instruct
# Embedders por tema (opcional; vacío => usa default)
EMBED_MODEL_PROGRAMMING=thenlper/gte-large
EMBED_MODEL_ELECTRONICS=intfloat/multilingual-e5-large-instruct
EMBED_MODEL_CHEMISTRY=hkunlp/instructor-large
# Reranker (cross-encoder)
RERANK_MODEL=jinaai/jina-reranker-v2-base-multilingual
# Alternativa: BAAI/bge-reranker-large
# RERANK_MODEL=BAAI/bge-reranker-v2-m3
# === Límites ===
CTX_TOKENS_SOFT_LIMIT=6000
MAX_CHUNKS_PER_FILE=3
HYBRID_DENSE_K=40
HYBRID_BM25_K=40
FINAL_TOPK=12

# fallback a BM25 si consulta < 4 tokens
BM25_FALLBACK_TOKEN_THRESHOLD=4

# ========= RETRIEVAL =========
HYBRID_ALPHA=0.5                 # mezcla dense/BM25 [0..1]
TOP_K=12                         # candidatos iniciales
TOP_K_PER_DOC=3                  # límite por archivo
TOP_K_RERANK=6                   # últimos que pasan al LLM
QUERY_SHORT_TOKENS=4             # fallback BM25 puro si < 4 tokens
CHUNK_SIZE=1200                  # caracteres
CHUNK_OVERLAP=120
MAX_CONTEXT_TOKENS=7000          # ventana dinámica (máx)
# Tokenizer (heurística si no disponible)
TOKENS_PER_CHAR=0.4


# === Qdrant ===
QDRANT_URL=http://qdrant:6333
QDRANT_STORAGE=/opt/iasantiago-rag/data/storage

# === BM25 (Whoosh) ===
BM25_BASE_DIR=/opt/iasantiago-rag/data/whoosh

# === Telemetría ===
TELEMETRY_PATH=/opt/iasantiago-rag/rag-api/retrieval.jsonl

# ========= OPENAI-COMPAT / TOPIC SELECTOR =========
TOPIC_BASE_DIR=/opt/iasantiago-rag/topics
# Etiquetas que verá Open WebUI en el desplegable de modelos
TOPIC_LABELS="Chemistry,Electronics,Programming"
# TOPIC_LABELS='{"Chemistry":"Química","Electronics":"Electrónica","Programming":"Programación"}'
# Nombre base visto por Open WebUI
OPENAI_BASE_NAME="topic"

# Cuando OWUI llama /v1/models, exponemos:
#   topic:Chemistry / topic:Electronics / topic:Programming

# ========= SECURITY / AUTH =========
# OAuth2 Proxy con Google Workspace
OAUTH2_EMAIL_DOMAIN=santiagoapostol.net
GOOGLE_CLIENT_ID=CHANGEME_GOOGLE_CLIENT_ID
GOOGLE_CLIENT_SECRET=CHANGEME_GOOGLE_CLIENT_SECRET
OAUTH2_REDIRECT_URL=https://iasantiago.santiagoapostol.net/oauth2/callback
GOOGLE_OIDC_ISSUER=https://accounts.google.com
OAUTH2_WHITELIST_GROUP= # opcional: gsuite group email
ALLOWED_EMAIL_DOMAIN=@santiagoapostol.net

# ========= NGINX SSL (self-signed o reales si tenéis CA interna)
SSL_CERT_PATH=/etc/nginx/ssl/iasantiago.crt
SSL_KEY_PATH=/etc/nginx/ssl/iasantiago.key

# === Open WebUI ===
OPENWEBUI_PORT=8080
OPENWEBUI_AUTH_PROVIDER=oidc
OPENWEBUI_OIDC_CLIENT_ID=${GOOGLE_CLIENT_ID}
OPENWEBUI_OIDC_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
OPENWEBUI_OIDC_ISSUER=${GOOGLE_OIDC_ISSUER}
OPENWEBUI_OIDC_REDIRECT_URI=https://iasantiago.santiagoapostol.net/_auth/callback
OPENWEBUI_OIDC_SCOPES=openid profile email
OPENWEBUI_API_BASE_URL=http://rag-api:8001/v1

# ========= EVALUACIÓN =========
EVAL_K=5
EVAL_CONCURRENCY=4

# ========= BACKUP =========
BACKUP_DIR=/opt/backups/rag-system


# === OpenAI compat ===
UPSTREAM_OPENAI_URL=http://vllm:8000/v1
OPENAI_API_KEY=dummy-key   # OpenWebUI requiere algo
